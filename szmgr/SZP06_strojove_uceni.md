---
title: "Strojov√© uƒçen√≠"
description: "TODO"
---

<dl><dt><strong>üìå NOTE</strong></dt><dd>

Strojov√© uƒçen√≠ a rozpozn√°v√°n√≠ vzor≈Ø: probl√©m klasifikace a regrese, shlukov√° anal√Ωza, uƒçen√≠ s uƒçitelem a bez uƒçitele. V√≠cevrstv√© neuronov√© s√≠tƒõ, v√≠cevrstv√© perceptrony, ztr√°tov√© funkce, zpƒõtn√° propagace. pass:[&lt;s>Hopfieldova s√≠≈•, &lt;/s>]konvoluƒçn√≠ s√≠tƒõ, rekurentn√≠ s√≠tƒõpass:[&lt;s>, samo-organizuj√≠c√≠ mapy&lt;/s>].

_PV021_

</dd></dl>

**üí° TIP**\
Velkou ƒç√°st zpracov√°n√≠ t√©hle ot√°zky jsem ukradl [s√°m sobƒõ](/fi/pv021/).

## Strojov√© uƒçen√≠ a rozpozn√°v√°n√≠ vzor≈Ø

- **Machine learning / strojov√© uƒçen√≠**

  Oblast informatiky zab√Ωvaj√≠c√≠ se konstrukc√≠ syst√©m≈Ø, kter√© nemaj√≠ svoji funkcionalitu explicitnƒõ naprogramovanou, ale nauƒç√≠ se ji a≈æ na z√°kladƒõ vstupn√≠ch dat. [ml](#ml) [pv021](#pv021)

  Pou≈æ√≠v√° se nap≈ô. pro:

  - filtrov√°n√≠ spamu v emailech,
  - rozpozn√°v√°n√≠ ≈ôeƒçi, rukopisu, tv√°≈ô√≠, zvuk≈Ø, atd.,
  - klasifikaci text≈Ø,
  - hern√≠ strategie,
  - anal√Ωzu trhu,
  - autonomn√≠ ≈ô√≠zen√≠ vozidel.

- **Rozpozn√°v√°n√≠ vzor≈Ø / pattern recognition**\
  Probl√©m automatizovan√©ho rozpozn√°v√°n√≠ vzor≈Ø v datech (nap≈ô. ƒç√≠slic v obr√°zku). P≈ô√≠klady jsou _klasifikace_, _regrese_ a _shlukov√° anal√Ωza_. [pattern-recognition](#pattern-recognition)
- **Klasifikace**\
  Probl√©m identifikace kategorie, do kter√© pat≈ô√≠ vstupn√≠ data. V√Ωstupem klasifikace je buƒè jedna konkr√©tn√≠ kategorie nebo vektor popisuj√≠c√≠ s jakou pravdƒõpodobnost√≠ vstup do ka≈æd√© kategorie pat≈ô√≠. [classification](#classification)
- **Regrese**\
  Probl√©m odhadu hodnoty nƒõjak√© promƒõnn√© na z√°kladƒõ znalosti jin√Ωch promƒõnn√Ωch. V√Ωstupem regrese je obvykle re√°ln√© ƒç√≠slo. [regression](#regression)

  Nap≈ô√≠klad p≈ôi _line√°rn√≠ regresi_ se sna≈æ√≠me data napasovat na p≈ô√≠mku -- naj√≠t jej√≠ offset a smƒõrnici. P≈ôi _logistick√© regresi_ chceme to sam√© ale m√≠sto p≈ô√≠mky m√°me logistic sigmoid. A tak d√°le. [pv021](#pv021)

- **Shlukov√° anal√Ωza / cluster analysis**\
  Vicedimenzion√°ln√≠ probl√©m rozdƒõlen√≠ vstupn√≠ch dat do skupin (shluk≈Ø) tak, aby data v jednom shluku byla _podobnƒõj≈°√≠_ sobƒõ ne≈æ dat≈Øm v jin√Ωch shluc√≠ch. [clustering](#clustering)

  Souvisej√≠c√≠m probl√©mem je vyj√°d≈ôen√≠ toho, ≈æe jsou si data v nƒõjak√©m smyslu _podobn√°_.

- **Supervised learning / uƒçen√≠ s uƒçitelem**\
  S√≠≈• se uƒç√≠ na z√°kladƒõ mno≈æiny tr√©novac√≠ch vstup≈Ø ve form√°tu (vstup, v√Ωstup). Supervised learning algoritmy se sna≈æ√≠ s√≠≈• modifikovat tak, aby vracela v√Ωstupy co mo≈æn√° nejpodobnƒõj≈°√≠ tƒõm tr√©novac√≠m. [pv021](#pv021)
- **Unsupervised learning / uƒçen√≠ bez uƒçitele**\
  S√≠≈• dost√°v√° jen vstupy. C√≠lem je z√≠skat o vstupn√≠ mno≈æinƒõ dat nƒõjakou u≈æiteƒçnou informaci, t≈ôeba kde jsou shluky. [pv021](#pv021)

## Neuronov√© s√≠tƒõ

- **Neural network / neuronov√° s√≠≈•**

  Neuronov√° s√≠≈• je mno≈æina propojen√Ωch neuron≈Ø, jej√≠≈æ chov√°n√≠ je zak√≥dov√°no do spojen√≠ mezi neurony. Je primitivn√≠m modelem biologick√Ωch neuronov√Ωch s√≠t√≠.

  Typ neuronov√© s√≠tƒõ je d√°n jej√≠ architekturou (zp≈Øsobem zapojen√≠), aktivitou (transformac√≠ vstup≈Ø na v√Ωstupy) a uƒçen√≠m (metodou zmƒõny vah p≈ôi tr√©nov√°n√≠).

- **Architektura**\
  Neuron m≈Ø≈æe b√Ωt _input_, _output_ nebo _hidden_. M≈Ø≈æe b√Ωt dokonce input i output najednou. Hidden je, pr√°vƒõ kdy≈æ nen√≠ input ani output.

  S√≠≈• b√Ωt cyklick√° -- _recurrent_ -- nebo acyklick√° -- _feed-forward_.

- **Stav s√≠tƒõ**\
  Vektor v√Ωstup≈Ø v≈°ech neuron≈Ø s√≠tƒõ (nejen output).
- **Stavov√Ω prostor s√≠tƒõ**\
  Mno≈æina v≈°ech mo≈æn√Ωch stav≈Ø s√≠tƒõ.
- **Vstup s√≠tƒõ**\
  Vektor re√°ln√Ωch ƒç√≠sel (prvek $\Reals^n$), kde $n$ je poƒçet vstup≈Ø.
- **Vstupn√≠ prostor s√≠tƒõ**\
  Mno≈æina v≈°ech vstup≈Ø s√≠tƒõ.
- **Inici√°ln√≠ stav**\
  Input neuron≈Øm je za v√Ωstup ($y$) d√°n vektor vstup≈Ø ($\vec{x}$). V≈°em ostatn√≠m neuron≈Øm je v√Ωstup ($y$) nastaven na 0.
- **V√Ωstup s√≠tƒõ**\
  Vektor v√Ωstup≈Ø ($y$) output neuron≈Ø. V√Ωstup se v pr≈Øbƒõhu v√Ωpoƒçtu m≈Ø≈æe mƒõnit.
- **V√Ωpoƒçet**\
  Typicky po diskr√©tn√≠ch kroc√≠ch:

  1. Zvol√≠ se mno≈æina neuron≈Ø (vybran√© podle pravidla dan√©ho architekturou).
  2. Zvolen√Ωm neuron≈Øm je nastaven v√Ωstup -- prostƒõ se vyhodnot√≠ aktivaƒçn√≠ funkce.
  3. Vra≈• se ke kroku 1.

     V√Ωpoƒçet je _koneƒçn√Ω_, pokud se stav s√≠tƒõ d√°le nemƒõn√≠ po koneƒçn√©m mno≈æstv√≠ opakov√°n√≠ postupu v√Ω≈°e.

- **Konfigurace**\
  Vektor hodnot v≈°ech vah.
- **Vahov√Ω prostor**\
  Mno≈æina v≈°ech konfigurac√≠.
- **Inici√°ln√≠ konfigurace**\
  Poƒç√°teƒçn√≠ hodnoty vah (ne≈æ zaƒçne tr√©nov√°n√≠).

## Multilayer perceptron (MLP) / v√≠cevrstv√© neuronov√© s√≠tƒõ

- **Perceptron -- jeden neuron**

  - Hrub√° matematick√° aproximace biologick√©ho neuronu.
  - Bin√°rn√≠ klasifik√°tor -- rozli≈°uje jestli vstup pat≈ô√≠ nebo nepat≈ô√≠ do nƒõjak√© jedn√© kategorie.[pv021](#pv021)
  - Liner√°n√≠ klasifik√°tor -- jeho funkce kombinuje vstupy line√°rnƒõ.

  ![width=400](./img/szp06_perceptron.png)

  - $x_i$ -- inputy
  - $w_i$ -- v√°hy
  - $\xi = w_0 + \sum_{i=1}^n w_i x_i$ -- vnit≈ôn√≠ potenci√°l
  - $y$ -- v√Ωstup
  - $y = \sigma(\xi)$ -- aktivaƒçn√≠ funkce ud√°vaj√≠c√≠ v√Ωstup
  - bias -- ud√°v√° "jak tƒõ≈æk√©" je pro neuron se aktivovat (ƒç√≠m vy≈°≈°√≠ ƒç√≠slo, t√≠m tƒõ≈æ≈°√≠ je pro neuron vydat nenulov√Ω v√Ωstup)
  - $x_0$ -- pro sna≈æ≈°√≠ implementaci se z√°v√°d√≠ dodateƒçn√Ω vstup, kter√Ω m√° v≈ædy hodnotu 1 a v√°hu rovnu -bias

  **üìå NOTE**\
  Vnit≈ôn√≠ potenci√°l funguje jako nadrovina (ƒç√°ra p≈ôi 2D, rovina p≈ôi 3D, nep≈ôedstaviteln√Ω mostrum ve vy≈°≈°√≠ch dimenz√≠), kter√° rozdƒõluje prostor vstup≈Ø na ƒç√°st, kde je $\xi &lt; 0$ a kde $\xi > 0$.

- **Multilayer perceptron (MLP)**

  MLP je feed-forward (neobsahuje cykly) architektura NN, kde plat√≠:

  - Neurony rozdƒõleny do vrstev -- jedn√© vstupn√≠, jedn√© v√Ωstupn√≠ a libovoln√©ho poƒçtu skryt√Ωch vrstev uprost≈ôed.
  - Vrstvy jsou _dense_ -- ka≈æd√Ω neuron v $i$-t√© vrstvƒõ je napojen na ka≈æd√Ω neuron v $(i + 1)$-n√≠ vrstvƒõ.

  ![width=400](./img/szp06_mlp.png)

  Kde:

  - $\textcolor{green}{X}$ -- mno≈æina input neuron≈Ø
  - $\textcolor{red}{Y}$ -- mno≈æina output neuron≈Ø
  - $Z$ -- mno≈æina v≈°ech neuron≈Ø
  - Neurony maj√≠ indexy $i$, $j$, ...
  - $\xi_j$ -- vnit≈ôn√≠ potenci√°l neuronu $j$ po skonƒçen√≠ v√Ωpoƒçtu
  - $y_j$ -- v√Ωstup neuronu $j$ po skonƒçen√≠ v√Ωpoƒçtu
  - $x_0 = 1$ -- hodnota form√°ln√≠ho jednotkov√©ho vstupu (kv≈Øli bias≈Øm)
  - $w_{j,i}$ -- v√°ha spojen√≠ **z** neuronu $i$ **do** neuronu $j$ (dst &lt;- src)
  - $w_{j,0} = -b_j$ -- bias -- v√°ha z form√°ln√≠ jednotky do neuronu $j$
  - $j_{\leftarrow}$ -- mno≈æina neuron≈Ø $i$, jen≈æ maj√≠ spojen√≠ **do** $j$ (j &lt;- i)
  - $j^{\rightarrow}$ -- mno≈æina neuron≈Ø $i$, do nich≈æ vede spojen√≠ **z** $j$ (j -> i)

### Aktivita

- **Pravidlo pro v√Ωbƒõr neuron≈Ø p≈ôi v√Ωpoƒçtu**\
  V i-t√©mu kroku vezmi i-tou vrstvu.
- **Vnit≈ôn√≠ potenci√°l neuronu $j$**\
  $\xi_j = \sum_{i \in j_{\leftarrow}} w_{ji}y_i$
- **Aktivaƒçn√≠ funkce neuronu $j$**\
  $\sigma_j : \Reals \to \Reals$ (t≈ôeba logistic sigmoid)
- **Stav nevstupn√≠ho neuronu $j$**\
  $y_j = \sigma_j(\xi_j)$ resp. $y_j(\vec{w}, \vec{x})$
- **Logistic sigmoid**\
  Vƒõt≈°ina aktivaƒçn√≠ch funkc√≠ vych√°z√≠ s funkce _sigmoid_. (Jsou _sigmoidn√≠_, vypadaj√≠ trochu jako p√≠smeno `S`). P≈ôid√°vaj√≠ do v√Ωpoƒçtu nelinearitu, kter√° je pot≈ôeba, aby NN mohla modelovat libovoln√© funkce. Z√°rove≈à je podobn√° klasick√©mu thresholdu, ale je "vyhlazen√°".

  ```math
  \sigma(\xi) = \frac{1}{1 + e^{-\lambda \cdot \xi}}
  ```

  kde $\lambda$ je _steepness_ parametr, kter√Ω urƒçuje, jak rychle sigmoid roste.

  ![width=400](./img/szp06_sigmoid.png)

### Tr√©nink

**‚ùó IMPORTANT**\
Pro likelihood viz ot√°zka [Statistika](../statistika/).

Neuronka je model, kde v√°hy neuron≈Ø jsou parametry. P≈ôi uƒçen√≠ neuronek je na≈°√≠m c√≠lem maximalizovat likelihood, jako≈æto m√≠ru toho, ≈æe na≈°e s√≠≈• sed√≠ na "namƒõ≈ôen√° data", training set $\cal T$. Tomuhle p≈ô√≠stupu se ≈ô√≠k√° _maximum likelihood principle_.

- **Training set $\cal T$**\
  je mno≈æina $p$ sampl≈Ø, kde $\vec{x} \in \Reals^{|X|}$ jsou vstupn√≠ vektory a $\vec{d} \in \Reals^{|Y|}$ jejich oƒçek√°v√°n√© v√Ωstupy.

  ```math
  \mathcal{T} = \{(\vec{x}_1, \vec{d}_1), (\vec{x}_2, \vec{d}_2), ..., (\vec{x}_p, \vec{d}_p)\}
  ```

- **Ztr√°tov√© funkce / loss function / error function**\
  Popisuje zp≈Øsob, jak√Ωm je p≈ôi tr√©ninku v√Ωstup z NN porovn√°n s oƒçek√°v√°n√Ωm v√Ωstupem.

  Jej√≠ volba z√°vis√≠ na tom, co NN modeluje. Nap≈ô. vol√≠me:

  - _mean squared error_ (MSE) -- pro regresi,

    ```math
    \begin{aligned}

    E_k(\vec{w}) &= \frac{1}{2} \sum_{j \in Y}
        \left(
            y_j(\vec{w}, \vec{x_k}) - d_{kj}
        \right)^2 \\

    E(\vec{w}) &= \textcolor{red}{\frac{1}{p}} \sum_{k=1}^p E_k(\vec{w})

    \end{aligned}
    ```

  - _(categorical) cross-entropy_ -- pro (multi-class) klasifikaci.

    ```math
    \begin{aligned}

    E(\vec{w}) = -\frac{1}{p} \sum_{k=1}^p \sum_{j \in Y} d_{kj} \ln(y_j)

    \end{aligned}
    ```

- **Gradient descent**\
  Algoritmus poƒç√≠taj√≠c√≠, jak se maj√≠ vahy neuron≈Ø upravit, aby se zmen≈°ila ztr√°ta. Vych√°z√≠ z gradientu ztr√°tov√© funkce.

  ```math
  \Delta \vec{w}^{(t)} = - \varepsilon(t) \cdot \nabla E (\vec{w}^{(t)})
  ```

- **Stochastic Gradient Descent (SGD)**\
  Sample nebere≈° po jednom ale po mal√Ωch randomizovan√Ωch v√°rk√°ch -- minibatch√≠ch $T$, a v√°hy upravuje≈° a≈æ po zpracov√°n√≠ minibatche.

  ```math
  \Delta \vec{w}^{(t)} = - \varepsilon(t) \cdot \sum_{k \in T} \nabla E_k(\vec{w}^{(t)})
  ```

- **Backpropagation / zpƒõtn√° propagace**\
  Technika, kdy se v pr≈Øbƒõhu _gradient descent_ ztr√°ta zp≈Øsoben√° konkr√©tn√≠m neuronem dedukuje na z√°kl√°dƒõ jeho p≈ô√≠spƒõvku k v√Ωsledku. Algoritmus tak postupuje od output vrstvy smƒõrem k input vrstvƒõ.
- **Learning rate $\varepsilon$**\
  Hyperparametr $0 &lt; \varepsilon \le 1$ ovliv≈àuj√≠c√≠ rychlost uƒçen√≠. M≈Ø≈æe z√°viset na iteraci $t$, pak je to funkce $\varepsilon(t)$.

**Gradient descent v MLP**

```math
\begin{aligned}

w_{ji}^{(t+1)}
&= w_{ji}^{(t)} + \Delta w_{ji}^{(t)} \\

\Delta w_{ji}^{(t)}
&= -\varepsilon(t) \cdot \textcolor{green}{\frac{\partial E}{\partial w_{ji}}(\vec{w}^{(t)})} \\

\textcolor{green}{\frac{\partial E}{\partial w_{ji}}}
&= \sum_{k=1}^{p} \textcolor{blue}{\frac{\partial E_k}{\partial w_{ji}}} \\

\textcolor{blue}{\frac{\partial E_k}{\partial w_{ji}}}
&= \textcolor{red}{\frac{\partial E_k}{\partial y_j}}
    \cdot \textcolor{purple}{\frac{\partial y_j}{\partial \xi_j}}
    \cdot \textcolor{teal}{\frac{\partial \xi_j}{\partial w_{ji}}} \\
&= \textcolor{red}{\frac{\partial E_k}{\partial y_j}}
    \cdot \textcolor{purple}{\sigma'_j(\xi_j)}
    \cdot \textcolor{teal}{y_i}
\end{aligned}
```

Za p≈ôedpokladu, ≈æe $E$ je squared error, pak:

**‚ö†Ô∏è WARNING**\
V p≈ô√≠padƒõ, ≈æe $E$ nen√≠ squared error, n√°sleduj√≠c√≠ v√Ωpoƒçet neplat√≠.

```math
\large
\textcolor{red}{\frac{\partial E_k}{\partial y_j}} =
\begin{cases}
    y_j - d_{kj} & \text{ pokud } j \in Y ; \\
    \sum_{r \in j^{\rightarrow}} \textcolor{brown}{\frac{\partial E_k}{\partial y_r}}
        \cdot \textcolor{dodgerblue}{\frac{\partial y_r}{\partial \xi_r}}
        \cdot \textcolor{forestgreen}{\frac{\partial \xi_r}{\partial y_j}}
    = \sum_{r \in j^{\rightarrow}} \textcolor{brown}{\frac{\partial E_k}{\partial y_r}}
        \cdot \textcolor{dodgerblue}{\sigma'_r(\xi_r)}
        \cdot \textcolor{forestgreen}{w_{rj}}
    & \text{ jinak}.
\end{cases}
```

**Algoritmus pro v√Ωpoƒçet $\frac{\partial E}{\partial w_{ji}}$**

1. Inicializuj $\varepsilon_{ji} := 0$.
2. forward pass -- vyhodno≈• NN pro sample $k$ (t.j. $y_j(\vec{w}, \vec{x_k})$ pro v≈°echny $j \in Z$)
3. backward pass -- od konce pro ka≈ædou vrstvu spoƒç√≠tej $\frac{\partial E_k}{\partial y_j}$
   a. pokud $j \in Y$, pak $\frac{\partial E_k}{\partial y_j} = y_j - d_{kj}$
   b. pokud $j \in Z \setminus Y \cup X $, a $j$ je v $l$-t√© vrstvƒõ, pak
   $\frac{\partial E_k}{\partial y_j} = \sum_{r \in j^{\rightarrow}} \frac{\partial E_k}{\partial y_r} \cdot \sigma'_r(\xi_r) \cdot w_{rj}$
4. weight update -- pro v≈°echna $w_{ji}$ spoƒç√≠tej
   $\frac{\partial E_k}{\partial w_{ji}} := \frac{\partial E_k}{\partial y_j} \cdot \sigma'_j(\xi_j) \cdot y_i$
5. $\varepsilon_{ji} := \varepsilon_{ji} + \frac{\partial E_k}{\partial w_{ji}}$
6. $\varepsilon_{ji}$ obsahuje v√Ωslednou hodnotu $\frac{\partial E}{\partial w_{ji}}$

## Konvoluƒçn√≠ s√≠tƒõ

Neuronov√© s√≠tƒõ uzp≈Øsoben√© ke zpracov√°n√≠ obrazu. M√≠sto n√°soben√≠ matic pou≈æ√≠vaj√≠ alespo≈à v jedn√© vrstvƒõ konvoluci. Konvoluƒçn√≠ s√≠tƒõ maj√≠ dva nov√© typy vrstev: _konvoluƒçn√≠_ a _pooling_, ale jinak se od klasick√Ωch MLP moc neli≈°√≠. Aktivace a tr√©nink z≈Østavaj√≠ v podstatƒõ stejn√©. [cnn](#cnn)

**‚ùó IMPORTANT**\
Pro konvoluci viz ot√°zka [Zpracov√°n√≠ rastrov√©ho obrazu](../zpracovani-rastroveho-obrazu/).

**Typical CNN by [Aphex34](https://commons.wikimedia.org/w/index.php?curid=45679374)**

![width=100%](./img/szp06_cnn.png)

- **Konvoluƒçn√≠ vrstva**
  - Ka≈æd√Ω neuron je napojen jen na mal√Ω _receptive field_ neuron≈Ø o vrstvu n√≠≈æe, kter√Ω se posouv√° o dan√Ω stride.
  - V√Ωstup z neuronu v konvoluƒçn√≠ vrstvƒõ je d√°n konvoluc√≠ jeho receptive field s v√°hami a p≈ôiƒçten√≠m biasu.
  - V≈°echny neurony v konvoluƒçn√≠ vrstvƒõ sd√≠l√≠ stejn√© v√°hy a biasy dan√© velikost√≠ receptive field, co≈æ jim umo≈æ≈àuje nauƒçit se nƒõjak√Ω vzor o velikosti receptive field -- ≈ô√≠k√°me, ≈æe takov√° vrstva je feature mapa.
  - Vzor≈Ø se chceme zpravidla nauƒçit v√≠ce, m√°me v√≠cero vz√°jemnƒõ nez√°visl√Ωch feature map napojen√Ωch na stejnou vstupn√≠ vrstvu.
- **Pooling vrstva**\
  Nemaj√≠ v√°hy. Slou≈æ√≠ ke sn√≠≈æen√≠ poƒçtu parametr≈Ø. Ka≈æd√Ω neuron poƒç√≠t√° nƒõjakou jednoduchou funkci na sv√©m _receptive field_:
  - _max-pooling_: maximum,
  - _L2-pooling_: square root of sum of squares,
  - _average-pooling_: mean.
- **Backpropagation**

  Algoritmus je pot≈ôeba trochu poupravit, aby podporovat konvoluƒçn√≠ a pooling vrstvy.

  U konvoluƒçn√≠ch vrstev nestaƒç√≠ pro ka≈ædou v√°hu $w_{ji}$ spoƒç√≠tat $\frac{\partial E_k}{\partial w_{ji}}$, proto≈æe pro ka≈ædou v√°hu existuje v√≠c ne≈æ jeden v√Ωstup $y_j$. Tedy:

  ```math
  \frac{\partial E_k}{\partial w_{ji}} = \sum_{rl \in \textcolor{red}{\bf \lbrack ji \rbrack}} \frac{\partial E_k}{\partial y_r}
      \cdot \sigma'_r(\xi_r)
      \cdot y_l
  ```

  kde $\color{red}\bf \lbrack ji \rbrack$ je mno≈æina spojen√≠ (dvojic neuron≈Ø) sd√≠l√≠c√≠ch v√°hu $w_{ji}$.

  Pokud $j \in Z \setminus Y$ a $j^{\rightarrow}$ je max-pooling, pak $j^{\rightarrow} = \{ i \}$ a plat√≠:

  ```math
  \frac{\partial E_k}{\partial y_j}
  = \begin{cases}
      \frac{\partial E_k}{\partial y_i} & \text{pokud } j = \argmax_{r \in i_{\leftarrow}} y_r \\
      0 & \text{jinak}
  \end{cases}
  ```

## Rekurentn√≠ s√≠tƒõ

Neuronov√© s√≠tƒõ, jejich≈æ architektura obsahuje cykly. Tedy v√Ωstup v jednom bodƒõ v ƒçase s√≠tƒõ p≈ôisp√≠v√° k v√Ωstup v budoucnosti. Jin√Ωmi slovy, je to neuronka s pamƒõt√≠. _Recurrent neural networks_ (RNN) konkr√©tnƒõ jsou MLP _minim√°lnƒõ_ roz≈°√≠≈ôen√© tak, aby mƒõly pamƒõ≈•. [rnn](#rnn)

- **V√Ωhody**

  - Um√≠ zpracovat vstupy s variabiln√≠, p≈ôedem nezn√°mou d√©lkou.
  - Velikost modelu (mno≈æiny vah) je fixn√≠ nez√°visle na velikosti vstupu.
  - V√°hy se sd√≠l√≠ mezi vstupy (nap≈ô. slova ve vƒõtƒõ), co≈æ umo≈æ≈àuje nauƒçit se nƒõjak√Ω kontext.

- **Nev√Ωhody**
  - Tr√©nov√°n√≠ je slo≈æitƒõj≈°√≠, proto≈æe se vyskytuje zpƒõtn√° vazba.
  - V√Ωpoƒçetnƒõ n√°roƒçnƒõj≈°√≠.
  - Gradient m≈Ø≈æe explodovat (exploding) nebo zaniknout (diminishing).

![width=100%](./img/szp06_rnn.png)

- **Notace**\
  V ƒçase $t$:

  - $\vec{x_t} = (x_{t, 1}, x_{t, 2}, ..., x_{t, M})$ je vstupn√≠ vektor p≈ôed√°van√Ω $M$ vstupn√≠m neuron≈Øm,
  - $\vec{h_t} = (h_{t, 1}, h_{t, 2}, ..., h_{t, H})$ je vektor hodnot $H$ skryt√Ωch neuron≈Ø,
  - $\vec{y_t} = (y_{t, 1}, y_{t, 2}, ..., y_{y, N})$ je v√Ωstupn√≠ vektor $N$ neuron≈Ø,
  - $U_{j, i}$ je v√°ha mezi inputem $i$ a hiddenem $j$,
  - $W_{j', i'}$ je v√°ha mezi hiddenem $i'$ a hiddenem $j'$,
  - $V_{j'', i''}$ je v√°ha mezi hiddenem $i''$ a outputem $j''$.

- **Aktivita**

  - Na poƒç√°tku je v√Ωstup neuronky vynulov√°n. Pamƒõ≈• je tedy pr√°zdn√°.
  - RNN zpracov√°v√° sekvenci vstup≈Ø $\mathbb{x} = \vec{x_1}, \vec{x_2}, ..., \vec{x_T}$ d√©lky $T$.
  - Pro ka≈æd√Ω prvek $\vec{x_t} \in \mathbb{x}$, s√≠≈• vyprodukuje v√Ωstup z hidden neuron≈Ø:

    ```math
    \vec{h_t} = \sigma(U \cdot \vec{x}_t + W \cdot \vec{h}_{t-1})
    ```

  - Pro v√Ωstup pak:

    ```math
    \vec{y_t} = \sigma(V \cdot \vec{h}_t)
    ```

- **Tr√©nink**

  Tr√©novac√≠ set je mno≈æina dvojic -- (vstupn√≠ **sekvence**, v√Ωstupn√≠ **sekvence**).

  ```math
  \mathcal{T} = \{ (\bold{x}_1, \bold{d}_1), ..., (\bold{x}_p, \bold{d}_p) \}
  ```

  **üìå NOTE**\
  Ano, to znamen√°, ≈æe $x_{lt1}$ je prvn√≠ prvek $t$-ho prvku v $l$-t√© vstupn√≠ sekvenci.

  Squared error samplu $(\bold{x}, \bold{d})$:

  ```math
  E_{(\bold{x}, \bold{d})} = \sum_{t=1}^T \sum_{k=1}^N \frac{1}{2} (y_{tk} - d_{tk})^2
  ```

  Gradient descent je podobn√Ω. Na zaƒç√°tku jsou v≈°echny v√°hy inicalizov√°ny pobl√≠≈æ 0 a pak iterativnƒõ p≈ôepoƒç√≠t√°v√°ny:

  ```math
  \begin{aligned}

  U_{kk'}^{(l+1)} &= U_{kk'}^{(l)} - \varepsilon(l) \cdot \frac{\partial E_{(x, d)}}{\partial U_{kk'}} \\
  V_{kk'}^{(l+1)} &= V_{kk'}^{(l)} - \varepsilon(l) \cdot \frac{\partial E_{(x, d)}}{\partial V_{kk'}} \\
  W_{kk'}^{(l+1)} &= W_{kk'}^{(l)} - \varepsilon(l) \cdot \frac{\partial E_{(x, d)}}{\partial W_{kk'}} \\

  \frac{\partial E_{(x, d)}}{\partial U_{kk'}} &= \sum_{t=1}^T
      \textcolor{brown}{\frac{\partial E_{(x, d)}}{\partial h_{tk}}}
      \cdot \sigma'
      \cdot x_{tk'} \\
  \frac{\partial E_{(x, d)}}{\partial V_{kk'}} &= \sum_{t=1}^T
      \textcolor{darkgreen}{\frac{\partial E_{(x, d)}}{\partial y_{tk}}}
      \cdot \sigma'
      \cdot h_{tk'} \\
  \frac{\partial E_{(x, d)}}{\partial W_{kk'}} &= \sum_{t=1}^T
      \textcolor{brown}{\frac{\partial E_{(x, d)}}{\partial h_{tk}}}
      \cdot \sigma'
      \cdot h_{(t-1)k'} \\

  \end{aligned}
  ```

  Za p≈ôedpokladu squared error je backpropagation:

  ```math
  \begin{aligned}
  \textcolor{darkgreen}{\frac{\partial E_{(x, d)}}{\partial y_{tk}}}
  &= y_{tk} - d_{tk} \\

  \textcolor{brown}{\frac{\partial E_{(x, d)}}{\partial h_{tk}}}
  &= \sum_{k'=1}^N
      \textcolor{darkgreen}{\frac{\partial E_{(x, d)}}{\partial y_{tk'}}}
      \cdot \sigma'
      \cdot V_{k'k}
  +
      \sum_{k'=1}^H
      \textcolor{brown}{\frac{\partial E_{(x, d)}}{\partial h_{(t+1)k'}}}
      \cdot \textcolor{red}{\sigma'
      \cdot W_{k'k}}
  \end{aligned}
  ```

  **üí° TIP**\
  Pokud $\textcolor{red}{\sigma' \cdot W_{k‚Äôk}} \not\approx 1$, pak gradient buƒè vybouchne nebo se ztrat√≠.

  - **Long Short-Term Memory (LSTM)**\
    LSTM ≈ôe≈°√≠ probl√©m s vanishing a exploding gradientem, kter√Ωm RNN. V RNN je $\sigma$ typicky $\tanh$. V LSTM obsahuje jeden hidden neuron vlastnƒõ ƒçty≈ôi "podvrstvy", kter√© mimo jin√© umo≈æ≈àuj√≠ ƒç√°st pamƒõti zapomenout:

    ![width=100%](./img/szp06_lstm.png)

## Zdroje

- [[[pv021, 1]]] T. Br√°zdil: PV021 Neural Networks
- [[[ml, 2]]] [Wikipedia: Machine learning](https://en.wikipedia.org/wiki/Machine_learning)
- [[[classification, 3]]] [Wikipedia: Statistical classification](https://en.wikipedia.org/wiki/Statistical_classification)
- [[[regression, 4]]] [Wikipedia: Regression analysis](https://en.wikipedia.org/wiki/Regression_analysis)
- [[[clustering, 5]]] [Wikipedia: Cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis)
- [[[pattern-recognition, 6]]] [Wikipedia: Pattern recognition](https://en.wikipedia.org/wiki/Pattern_recognition)
- [[[hopfield, 7]]] [Wikipedia: Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network)
- [[[hebb, 8]]] [Wikipedia: Hebbian theory](https://en.wikipedia.org/wiki/Hebbian_theory)
- [[[cnn, 9]]] [Wikipedia: Convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network)
- [[[rnn, 10]]] [Wikipedia: Recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network)
- [[[som, 11]]] [Wikipedia: Self-organizing map](https://en.wikipedia.org/wiki/Self-organizing_map)
- [[[som-tutorial, 12]]] [Self-Organizing Maps: Tutorial](https://sites.pitt.edu/~is2470pb/Spring05/FinalProjects/Group1a/tutorial/som.html)
- [[[som-sdl, 13]]] [SDL Component Suite: Kohonen Network](http://www.lohninger.com/helpcsuite/kohonen_network_-_background_information.htm)
