---
title: "Statistika"
description: "TODO"
---

<dl><dt><strong>ğŸ“Œ NOTE</strong></dt><dd>

DiskrÃ©tnÃ­ a spojitÃ© nÃ¡hodnÃ© veliÄiny (NV), zÃ¡kladnÃ­ rozloÅ¾enÃ­. ÄŒÃ­selnÃ© charakteristiky NV. CentrÃ¡lnÃ­ limitnÃ­ vÄ›ta. BodovÃ© odhady, intervaly spolehlivosti, testovÃ¡nÃ­ statistickÃ½ch hypotÃ©z, hladina vÃ½znamnosti. ZÃ¡kladnÃ­ parametrickÃ© a neparametrickÃ© testy, ANOVA, testy nezÃ¡vislosti NV. LineÃ¡rnÃ­ regrese, celkovÃ½ F-test, dÃ­lÄÃ­ t-testy.

_MV013_

</dd></dl>

**OpakovÃ¡nÃ­**

**ğŸ’¡ TIP**\
Viz bakalÃ¡Å™skÃ© otÃ¡zky [Kombinatorika a pravdÄ›podobnost](../../szb/kombinatorika-a-pravdepodobnost/) a [Statistika](../../szb/statistika/).

- **Statistika**\
  ZabÃ½vÃ¡ se sbÃ­rÃ¡nÃ­m, organizacÃ­, analÃ½zou, interpretacÃ­ a prezentacÃ­ dat. [statistics](#statistics)

  - _PopisnÃ¡ / decriptive_: shrnuje data, kterÃ¡ mÃ¡me,
  - _InferenÄnÃ­ / inferential_: pÅ™edpoklÃ¡dÃ¡, Å¾e data kterÃ¡ mÃ¡me jsou jen souÄÃ¡stÃ­ celku; pracuje s modely celÃ© populace a hypotÃ©zami o nÃ­.

- **ZÃ¡kladnÃ­ prostor $\Omega$**\
  KoneÄnÃ¡ mnoÅ¾ina moÅ¾nÃ½ch jevÅ¯. NapÅ™ $\{1, 2, 3, 4, 5, 6\}$ pro moÅ¾nÃ© hody Å¡estistÄ›nkou.
- **MoÅ¾nÃ½ vÃ½sledek (elementÃ¡rnÃ­ nÃ¡hodnÃ½ jev) $\omega_k$**\
  Prvek zÃ¡kladnÃ­ho prostoru $\Omega$.
- **NÃ¡hodnÃ½ jev (event) $A$**\
  PodmnoÅ¾ina $A \sube \Omega$, kterÃ¡ nÃ¡s zajÃ­mÃ¡. NapÅ™. _"Na Å¡estistÄ›nce padne sudÃ© ÄÃ­slo."_

## NÃ¡hodnÃ© veliÄiny

- **NÃ¡hodnÃ¡ veliÄina (NV) / random variable**\
  NÄ›co, co se dÃ¡ u kaÅ¾dÃ©ho moÅ¾nÃ©ho vÃ½sledku zmÄ›Å™it. ZobrazenÃ­ z prostoru elementÃ¡rnÃ­ch jevÅ¯ do mÄ›Å™itelnÃ©ho prostoru $E$ (tÅ™eba $\mathbb{R}$).

  $X : \Omega \to \mathbb{E}$

### DiskrÃ©tnÃ­

DiskrÃ©tnÃ­ NV je nÃ¡hodnÃ¡ veliÄina, kterÃ¡ nabÃ½vÃ¡ koneÄnÄ› nebo spoÄetnÄ› mnoha hodnot. $\mathbb{E}$ je koneÄnÃ¡ nebo spoÄetnÃ¡, napÅ™. $\N$.

PÅ™Ã­klad: hodnota na Å¡estistÄ›nce.

JinÃ½mi slovy, NV $X : \Omega \to \R$ je _diskrÃ©tnÃ­_, pokud se prvky $\Omega$ zobrazÃ­ do $\R$ jako izolovanÃ© body $\{x_1, x_2, \ldots\}$.

- **RozdÄ›lenÃ­ pravdÄ›podobnosti**\
  Funkce $P(X) : \mathbb{E} \to \R$, kterÃ¡ kaÅ¾dÃ© hodnotÄ› popsanÃ© veliÄinou $X$ pÅ™iÅ™azuje pravdÄ›podobnost jejÃ­ho vÃ½skytu.

- KaÅ¾dÃ¡ $x_i$ mÃ¡ nenulovou pravdÄ›podobnost:

  ```math
  P(x_i) > 0
  ```

- SouÄet pravdÄ›podobnostÃ­ vÅ¡ech moÅ¾nÃ½ch hodnot $x_i$ je $1$:

  ```math
  \sum_{x} P(x_i) = 1
  ```

### SpojitÃ©

SpojitÃ¡ NV je nÃ¡hodnÃ¡ veliÄina, kterÃ¡ nabÃ½vÃ¡ aÅ¾ nespoÄetnÄ› nekoneÄnÄ› mnoha hodnot. Tedy $\mathbb{E}$ je nespoÄetnÃ¡, napÅ™. $\R$.

PÅ™Ã­klad: doba ÄekÃ¡nÃ­ na Å¡alinu, analogovÃ½ signÃ¡l, vÃ½Å¡ka ÄlovÄ›ka (pokud mÃ¡me fakt dobrej metr).

JinÃ½mi slovy, NV $X : \Omega \to \R$ je _spojitÃ¡_, pokud se prvky $\Omega$ zobrazÃ­ do $\R$ jako interval $\lbrack a, b \rbrack$.

- **Hustota pravdÄ›podobnosti / probability density function (PDF)**\
  Funkce $f(x) : \mathbb{E} \to \R$, kterÃ¡ kaÅ¾dÃ© hodnotÄ› popsanÃ© veliÄinou $X$ pÅ™iÅ™azuje pravdÄ›podobnost jejÃ­ho vÃ½skytu.

- KaÅ¾dÃ½ bod tohoto intervalu mÃ¡ **nulovou** pravdÄ›podobnost:

  ```math
  f(x) = 0
  ```

- NicmÃ©nÄ› integrÃ¡l pravdÄ›podobnostnÃ­ funkce $f(x)$ je $1$:

  ```math
  \int_{-\infty}^{\infty} f(x) dx = 1
  ```

- PravdÄ›podobnost, Å¾e NV nabÃ½vÃ¡ hodnoty z intervalu $\lbrack a, b \rbrack$ je pak:

  ```math
  P(a \leq X \leq b) = \int_{a}^{b} f(x) dx
  ```

### ZÃ¡kladnÃ­ rozloÅ¾enÃ­

- **DistribuÄnÃ­ funkce / cumulative distribution function (CDF)**

  Funkce $F(X) : \mathbb{E} \to \R$ udÃ¡vÃ¡ pravdÄ›podobnost, Å¾e NV $X$ nabÃ½vÃ¡ hodnoty menÅ¡Ã­ neÅ¾ $x$.

  ```math
  \begin{align*}

  F(x) &= P(X \leq x) & \text{pro diskrÃ©tnÃ­ NV} \\
  F(x) &= \int_{-\infty}^{x} f(x) dx & \text{pro spojitÃ© NV}

  \end{align*}
  ```

  Charakterizuje rozdÄ›lenÃ­, kterÃ©mu nÃ¡hodnÃ¡ veliÄina $X$ podlÃ©hÃ¡.

  Pro spojitÃ© NV je to plocha pod kÅ™ivkou pravdÄ›podobnostnÃ­ funkce. A taky se dÃ¡ pouÅ¾Ã­t k vyjÃ¡dÅ™enÃ­ pravdepodobnosti:

  ```math
  P(a \leq X \leq b) = F(b) - F(a)
  ```

**DiskrÃ©tnÃ­ rozloÅ¾enÃ­**

| NÃ¡zev                                                                                    |
| ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | ---------------------------------- |
| Definice                                                                                 | Popis                                                                                                                                                                                                                                                      | PÅ™Ã­klad                                                                                                     | Bernoulliho / alternativnÃ­         |
| $ P(x) = \begin{cases} 1 - p & x \ne 1 \\ p & x = 1 \\ \end{cases} $                     | NÃ¡hodnÃ½ pokus, kde jsou jen dva moÅ¾nÃ© vÃ½sledky.                                                                                                                                                                                                            | Hod mincÃ­.                                                                                                  | BinomickÃ©                          |
| $ P(x, n, p) = \binom{n}{x} p^x (1-p)^{n-k} $                                            | Sekvence $n$ pokusÅ¯. Popisuje pravdÄ›podobnost, Å¾e $x$ bude ÃºspÄ›Å¡nÃ½ch.                                                                                                                                                                                      | Hod mincÃ­ $n$ krÃ¡t.                                                                                         | Poissonovo                         |
| $ P(k, \lambda) = \frac{\lambda^k e^{-\lambda}}{k!} $                                    | Pokud se nÄ›co dÄ›je prÅ¯mÄ›rnÄ› $\lambda$-krÃ¡t za jednotku Äasu, jakÃ¡ je pravdÄ›podobnost, Å¾e se to stane $k$-krÃ¡t za stejnou jednotku Äasu? VÃ½skyt jednoho jevu nesmÃ­ ovlivnit pravdÄ›podobnost nÃ¡sledujÃ­cÃ­ho vÃ½skytu a takÃ© se nemohou stÃ¡t dva jevy najednou. | Kolik lidÃ­ pÅ™ijde do obchodu za hodinu. _(Za pÅ™edpokladu, Å¾e je pandemie a dovnitÅ™ mÅ¯Å¾e jen jeden ÄlovÄ›k.)_ | GeometrickÃ©                        |
| $ P(k, p) = \begin{cases} p (1-p)^k & k = 0, 1, ... \\ 0 & \text{jinak} \\ \end{cases} $ | KdyÅ¾ tÄ› zajÃ­mÃ¡, jakÃ¡ je Å¡ance, Å¾e se nÄ›co pokazÃ­ $k$ krÃ¡t, neÅ¾ to koneÄnÄ› uspÄ›je.                                                                                                                                                                          | KolikrÃ¡t musÃ­Å¡ hodit mincÃ­, neÅ¾ padne poprvÃ© hlava.                                                         | (DiskrÃ©tnÃ­) rovnomÄ›rnÃ© / uniformnÃ­ |

**SpojitÃ© rozloÅ¾enÃ­**

| NÃ¡zev                                                                                                                                                                             |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | -------------------------------- |
| Definice                                                                                                                                                                          | Popis                                                                                                                                                                                                             | PÅ™Ã­klad                                   | (SpojitÃ©) rovnomÄ›rnÃ© / uniformnÃ­ |
| $ f(x) = \begin{cases} \frac{1}{b-a} & a \le x \le b \\ 0 & x &lt; a \lor x > b \\ \end{cases} $                                                                                  | VÅ¡echny jevy v danÃ©m intervalu $(a, b)$ (mÅ¯Å¾e bÃ½t otevÅ™enÃ½ nebo uzavÅ™enÃ½) jsou stejnÄ› pravdÄ›podobnÃ©.                                                                                                              | Bod na kruÅ¾nici.                          | ExponenciÃ¡lnÃ­                    |
| $ f(x, \lambda) = \begin{cases} \lambda e^{-\lambda x} & x \ge 0 \\ 0 & x &lt; 0 \\ \end{cases} $                                                                                 | ÄŒas mezi jevy v PoissonovÄ› procesu.                                                                                                                                                                               | Jak dlouho budeÅ¡ Äekat na Å¡alinu.         | NormÃ¡lnÃ­ / Gaussovo              |
| $ f\_\mathcal{N}(x, \mu, \sigma^2) = \frac{1}{\sigma \sqrt{2 \pi}} e^{ -\frac {\left(x - \mu \right)^2} {2\sigma^2} } $                                                           | PouÅ¾Ã­vÃ¡ se jako default, kdyÅ¾ nevÃ­Å¡, jakou mÃ¡ promÄ›nnÃ¡ distribuci, kvÅ¯li centrÃ¡lnÃ­ limitnÃ­ vÄ›tÄ›. ($\mu$ je mean, $\sigma^2$ je rozptyl).                                                                          | VÃ½Å¡ka lidÃ­.                               | StandardnÃ­ normÃ¡lnÃ­              |
| $ f(x) = f\_\mathcal{N}(x, 0, 1) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} $                                                                                                    | Je fajn, protoÅ¾e mÃ¡ standardnÃ­ odchylku rovnu jednÃ©, takÅ¾e ÄlovÄ›ku staÄÃ­ si pamatovat, Å¾e: _ 68 % je v intervalu $(-1, 1)$, _ 95 % je v intervalu $(-2, 2)$, \* 99,7 % je v intervalu $(-3, 3)$.                  | VÃ½Å¡ka lidÃ­ (ale pÅ™eÅ¡kÃ¡lovanÃ¡).            | Cauchy                           |
| $ f(x) = \frac{1}{ \pi \sigma \left\lbrack 1 + \left( \frac{x - \mu}{\sigma} \right)^2 \right\rbrack } $                                                                          | PomÄ›r dvou spojitÃ½ch nÃ¡hodnÃ½ch promÄ›nnÃ½ch s normÃ¡lnÃ­m rozdÄ›lenÃ­m. Expected value ani rozptyl na nÃ­ nejsou definovanÃ©.                                                                                             | PomÄ›r vÃ½Å¡ky k Å¡Ã­Å™ce obliÄeje.             | Gamma                            |
| $ f(x, \alpha, \beta) = \begin{cases} \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha - 1} e^{-\beta x} & x > 0 \\ 0 & \text{jinak} \\ \end{cases} $                                | KdyÅ¾ mÃ¡Å¡ sekvenci jevÅ¯, kde ÄekacÃ­ doba na kaÅ¾dÃ½ mÃ¡ exponenciÃ¡lnÃ­ rozdÄ›lenÃ­ s rate $\beta$, pak ÄekacÃ­ doba na $n$-tÃ½ jev mÃ¡ Gamma rozdÄ›lenÃ­ s $\alpha = n$.                                                      | Jak dlouho budeÅ¡ Äekat na $n$-tou Å¡alinu. | $\chi^2$ (Chi-square)            |
| $ f(x, n) = \begin{cases} { \Large \frac{ x^{\frac{n}{2} - 1} e^{-\frac{x}{2}} }{ 2^\frac{n}{2} \Gamma\left( \frac{k}{2} \right) } } & x > 0 \\ 0 & \text{jinak} \\ \end{cases} $ | PouÅ¾Ã­vÃ¡ se pÅ™i testovÃ¡nÃ­ hypotÃ©z. NechÅ¥ $Z_1, Z_2, ..., Z_n$ jsou nezÃ¡vislÃ© nÃ¡hodnÃ© promÄ›nnÃ© se standardnÃ­m normÃ¡lnÃ­m rozdÄ›lenÃ­m a $X = \sum_{i=1}^n Z_i^2$, pak $X$ mÃ¡ $\chi^2$ rozdÄ›lenÃ­ s $n$ stupni volnosti. | TestovÃ¡nÃ­, jestli je mince fÃ©rovÃ¡.        | Studentovo $t$                   |

### ÄŒÃ­selnÃ© charakteristiky

StejnÄ› jako nÃ¡hodnÃ© veliÄiny popisujÃ­ jevy, ÄÃ­selnÃ© charakteristiky popisujÃ­ chovÃ¡nÃ­ nÃ¡hodnÃ½ch veliÄin... pomocÃ­ ÄÃ­sel.

#### MÃ­ry polohy

- **StÅ™ednÃ­ hodnota / mean / expected value**\
  PrÅ¯mÄ›r hodnot veliÄiny vÃ¡Å¾enÃ½ jejich pravdÄ›podobnostÃ­. ZnaÄÃ­ se $\overline{X}$ nebo $E(X)$.

  **ğŸ“Œ NOTE**\
   Taky nÄ›kdy oznaÄovanÃ½ jako _obecnÃ½ moment prvnÃ­ho Å™Ã¡du / prvnÃ­ obecnÃ½ moment_. [moment](#moment)

- **$\alpha$-kvantil $Q_\alpha$**\
  DÄ›lÃ­ statickÃ½ soubor na stejnÄ› velkÃ© ÄÃ¡sti.
- **MediÃ¡n**\
  ProstÅ™ednÃ­ prvek uspoÅ™Ã¡danÃ©ho statistickÃ©ho souboru. Kvantil $Q_{0.5}$.

  ```math
  \tilde{x} = \begin{cases}
      x_{\frac{n+1}{2}} & \text{pro lichÃ© }n\\
      \frac{1}{2} (x_\frac{n}{2} + x_{\frac{n}{2} + 1}) & \text{pro sudÃ© }n
  \end{cases}
  ```

- **Percentil**\
  VÃ½bÄ›rovÃ½ kvantil ($p$-tÃ½ kvantil, kde $0 &lt; p &lt; 1$) $Q_p$.
- **Modus**\
  Hodnota s nejvÄ›tÅ¡Ã­ ÄetnostÃ­.

#### MÃ­ry variability

Jak moc se od sebe prvky liÅ¡Ã­ (nezÃ¡visle na konstantnÃ­m posunutÃ­)?

- **Rozpyl / variance**\
  VyjadÅ™uje, jak moc se NV odchyluje od svÃ© stÅ™ednÃ­ hodnoty. ZnaÄÃ­ se $\sigma^2$, $\text{var}(X)$ nebo $D(X)$.

  ```math
  \text{var}(X) = E\left((x_i - E(X))^2\right)
  ```

  **ğŸ“Œ NOTE**\
   Taky nÄ›kdy oznaÄovanÃ½ jako _centrÃ¡lnÃ­ moment druhÃ©ho Å™Ã¡du / druhÃ½ centrÃ¡lnÃ­ moment_. [moment](#moment)

- **SmÄ›rodatnÃ¡ odchylka / standard deviation**\
  MÃ­ra variability NV. ZnaÄÃ­ se $\sigma$ nebo $\text{SD}(X)$. Je definovanÃ¡ jako $\sqrt{\sigma^2}$.
- **ovariance veliÄin $X$ a $Y$**\
  MÄ›Å™Ã­ urÄitou podobnost mezi $X$ a $Y$.

  ```math
  \text{cov}(X, Y) = E((X - E(X)) \cdot (Y - E(Y)))
  ```

  Ze vzorce vÃ½Å¡e plyne

  ```math
  \begin{aligned}
      \text{cov}(X, X) &= \text{var}(X) \\
      \text{cov}(X, Y) &= \text{cov}(Y, X) \\
      \text{cov}(X, Y) &= E(X \cdot Y) - E(X) \cdot E(Y)
  \end{aligned}
  ```

- **Korelace**\
  MÃ­ra podobnosti $\rho_{X, Y}$ nÃ¡hodnÃ½ch veliÄin $X$ a $Y$. Pokud $X = X$, pak $\rho_{X, X} = 1$. Pokud jsou $X$ a $Y$ nezÃ¡vislÃ©, pak $\rho_{X, Y} = 0$.

  ```math
  \rho_{X, Y} = \frac{\text{cov}(X, Y)}{\sqrt{\text{var}(X)} \cdot \sqrt{\text{var}(Y)}}
  = \frac{E((X - E(X)) \cdot (Y - E(Y)))}{\sqrt{\text{var}(X)} \cdot \sqrt{\text{var}(Y)}}
  ```

#### MÃ­ry tvaru

- **Koeficient Å¡ikmosti / skewness**\
  Vztah polohy meanu vÅ¯Äi mediÃ¡nu. VyjadÅ™uje symetrii dat.
- **Koeficient Å¡piÄatosti / kurtosis**\
  Jak vysokÃ½ je peak? Jak moc je to rozplÃ¡clÃ©.

## CentrÃ¡lnÃ­ limitnÃ­ vÄ›ta (CLV) / Central limit theorem (CLT)

S rostoucÃ­m poÄtem sample vÃ½sledkÅ¯ $X_i$ se jejich distribuce blÃ­Å¾Ã­ normÃ¡lnÃ­mu rozdÄ›lenÃ­ bez ohledu na jejich pÅ¯vodnÃ­ rozdÄ›lenÃ­.

Popisuje chovÃ¡nÃ­ _vÃ½bÄ›rovÃ©ho prÅ¯mÄ›ru_ pro velkÃ© soubory vzorkÅ¯ a umoÅ¾Åˆuje tak sestrojenÃ­ intervalovÃ½ch odhadÅ¯.

- **Moivreova-Laplacova vÄ›ta**

  MÄ›jme NV $X$. Pokud je $X$ souÄtem $n$ vzÃ¡jemnÄ› nezÃ¡vislÃ½ch NV $X_1, X_2, ..., X_n$ s Bernoulliho rozdÄ›lenÃ­m s parametrem $\pi$, mÃ¡ $X$ binomickÃ© rozdÄ›lenÃ­ s parametry $n$ a $\pi$, pak s $n \to \infty$:

  ```math
  \frac{X - n \pi}{\sqrt{n \pi (1 - \pi)}} \approx N(0, 1)
  ```

- **LÃ©vyho-Lindenbergova vÄ›ta**

  **ğŸ’¡ TIP**\
  ZobecnÄ›nÃ­ Moivreovy-Laplacovy vÄ›ty.

  MÄ›jme NV $X$. Pokud je $X$ souÄtem $n$ vzÃ¡jemnÄ› nezÃ¡vislÃ½ch NV $X_1, X_2, ..., X_n$ se shodnÃ½m rozdÄ›lenÃ­m libovolnÃ©ho typu, s koneÄnou stÅ™ednÃ­ hodnotou $E(X_i) = \mu$ a koneÄnÃ½m rozptylem $D(X_i) = \sigma^2$, pak pro normovanou NV $U$ asymptoticky s $n \to \infty$ platÃ­:

  ```math
  \begin{aligned}

  \overline{X} = \frac{1}{n} \sum_{i=1}^n X_i &\approx N \left( \mu, \frac{\sigma^2}{n} \right) \\

  \sqrt{n} \frac{\overline{X} - \mu}{\sqrt{\sigma^2}} &\approx N(0, 1) \\

  \frac{\sum_{i=1}^n X_i - n \mu}{\sqrt{n \sigma^2}} &\approx N(0, 1)

  \end{aligned}
  ```

  **VÃ½poÄet s CLV**

  NechÅ¥ $X$ je nÃ¡hodnÃ¡ promÄ›nnÃ¡ popisujÃ­ jak padÃ¡ 6, kdyÅ¾ hodÃ­me kostkou 100krÃ¡t. Tedy:

  ```math
  X \approx \text{Binomial} \left( 100, \frac{1}{6} \right)
  ```

  Podle CLV mÃ¡ $X$ asymptoticky $X \approx N(\frac{100}{6},\frac{500}{36})$.

  Pak napÅ™Ã­klad pravdÄ›podobnost, Å¾e Å¡estka padne mÃ©nÄ› neÅ¾ 16krÃ¡t je:

  ```math
  \begin{aligned}

  P(X < 16) &\doteq P(X \leq 16) = 0.429 \\
  P(X < 16) = P(X \leq 15) &\doteq F(X \leq 15) = 0.327 \\

  \end{aligned}
  ```

  S _continuity correction_ (opravou v dÅ¯sledku zmÄ›ny z diskrÃ©tnÃ­ na spojitou NV) je to:

  ```math
  P(X < 16) = P(X \leq 15.5) \doteq F(15.5) = 0.377
  ```

## Odhady

- **Odhad parametru / parameter estimation**\
  KdyÅ¾ se snaÅ¾Ã­Å¡ vymyslet, jakÃ© asi hodnoty majÃ­ parametery tÃ© kterÃ© distribuce mÃ­t, aby co nejlÃ­p pasovala na tvoje samply.

  CÃ­lem odhadu je urÄit parametry rozdÄ›lenÃ­ NV $X$ na zÃ¡kladÄ› informace z vÃ½bÄ›rovÃ©ho souboru (realizaci NV, datasetu). Chceme hodnotu a pÅ™esnost odhadu.

- **Metoda odhadu / estimator**\
  Popisuje, jak odhad zÃ­skat.
- **NestrannÃ½ odhad / unbiased estimator**\
  Metoda odhadu parametru $\theta$ takovÃ¡, Å¾e stÅ™ednÃ­ hodnota odhadu je rovna $\theta$. Nestrannost je celkem rozumnÃ© omezenÃ­, protoÅ¾e nechceme, aby byl odhad odchÃ½lenÃ½.
- **NejlepÅ¡Ã­ nestrannÃ½ odhad / best unbiased estimator**\
  NestrannÃ½ odhad, kterÃ½ mÃ¡ nejmenÅ¡Ã­ rozptyl ze vÅ¡ech nestrannÃ½ch odhadÅ¯.
- **KonzistentnÃ­ odhad / consistent estimator**\
  Metoda odhadu parametru $\theta$ takovÃ¡, Å¾e s poÄtem vzorkÅ¯ $n$ konverguje k $\theta$ pro $n \to \infty$. [consistent-estimator](#consistent-estimator)
- **(VÃ½bÄ›rovÃ¡) statistika / (sample) statistic**\
  NÃ¡hodnÃ¡ veliÄina dÃ¡na funkcÃ­, kterÃ¡ bere vÃ½bÄ›rovÃ½ soubor a vracÃ­ ÄÃ­slo. MÃ¡me napÅ™Ã­klad:

  - _VÃ½bÄ›rovÃ½ prÅ¯mÄ›r / sample mean_,
  - _VÃ½bÄ›rovÃ½ rozptyl / sample variance_,
  - _VÃ½bÄ›rovou smÄ›rodatnou odchylku / sample standard deviation_,
  - _VÃ½bÄ›rovou (empirickou) distribuÄnÃ­ funkci / sample distribution function_.

  > NÃ¡hodnÃ¡ veliÄina $T_n$, kterÃ¡ vznikne aplikacÃ­ funkce $T$ na nÃ¡hodnÃ½ vÃ½bÄ›r o velikosti $n$ $\mathbf{X} = (X_1, X_2, \ldots, X_n)$ se nazÃ½vÃ¡ statistika.
  >
  > ```math
  > T_n = T(X_1, X_2, \ldots, X_n)
  > ```

  **ğŸ’¡ TIP**\
   _Estimator_ je funkce poÄÃ­tajÃ­cÃ­ statistiku pouÅ¾itÃ¡ k odhadu parametru. [statistic](#statistic)

- **BodovÃ½ odhad / point estimate / pointwise estimate**\
  Odhad parametru danÃ½ **jednou hodnotou**, kterÃ¡ hodnotu parametru aproximuje.
- **IntervalovÃ½ odhad / interval estimate**\
  Odhad parametru danÃ½ pomocÃ­ **intervalu hodnot**, kterÃ½ hodnotu parametru s velkou pravdÄ›podobnostÃ­ obsahuje. DÃ©lka intervalu vypovÃ­dÃ¡ o pÅ™esnosti odhadu.
- **Interval spolehlivosti / confidence interval**\
  Interval spolehlivosti parametru $\theta$ s hladinou spolehlivosti $1 - \alpha$, kde $\alpha \in \lbrack 0, 1 \rbrack$ je dvojice statistik $\lbrack \theta_L, \theta_U \rbrack$ takovÃ¡, Å¾e:

  ```math
  P(\theta_L < \theta < \theta_U) = 1 - \alpha
  ```

  kde $\theta_L$ je **dolnÃ­ mez intervalu** a $\theta_U$ je **hornÃ­ mez intervalu**.

- **Hladina vÃ½znamnosti a spolehlivosti / significance and confidence level**
  - Hladina vÃ½znamnosti $\alpha$ je pravdÄ›podobnost, Å¾e parametr **nespadÃ¡** do intervalovÃ©ho odhadu.
  - Hladina spolehlivosti $1 - \alpha$ je pravdÄ›podobnost, Å¾e parametr **spadÃ¡** do intervalovÃ©ho odhadu.
- **LevostrannÃ½, pravostrannÃ½ a oboustrannÃ½ interval / left-tailed, right-tailed and two-tailed interval**
  - _LevostrannÃ½ (dolnÃ­)_: $P(\theta \le \theta_L) = 1 - \alpha$.
  - _PravostrannÃ½ (hornÃ­)_: $P(\theta \ge \theta_U) = 1 - \alpha$.
  - _OboustrannÃ½_: $P(\theta \le \theta_L) = P(\theta \ge \theta_U) = \frac{\alpha}{2}$.

**Tvorba intervalovÃ©ho odhadu**

MÃ¡me vzorek velikosti $n$ s vÃ½bÄ›rovÃ½m prÅ¯mÄ›rem $\overline{X}$ a vÃ½bÄ›rovÃ½m rozptylem $S^2$. OdhadnÄ›te stÅ™ednÃ­ hodnotu $\mu$ s hladinou spolehlivosti 0.95, pokud vÃ­te, Å¾e $X \approx N(\mu, \sigma^2)$, kde rozptyl $\sigma^2$ je neznÃ¡mÃ½.

1. ZvolÃ­me vhodnou vÃ½bÄ›rovou statistiku $T(X)$ jejÃ­Å¾ rozdÄ›lenÃ­ zÃ¡vislÃ© na $\mu$ znÃ¡me. V tomhle pÅ™Ã­padÄ› StudentÅ¯v t-test:

   ```math
   T(X) = \frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t_{n - 1}
   ```

   Tedy vÃ­me, Å¾e $T(X) \sim t(n-1)$

2. UrÄÃ­me kvantily $t_\frac{\alpha}{2} = t_{0.025}$ a $t_{1 - \frac{\alpha}{2}} = t_{0.975}$ z $T(X)$:

   ```math
   \begin{aligned}

   P(t_{0.025}(n - 1) < T(X) < t_{0.975}(n-1)) &= 1 - \alpha = 0.95 \\

   t_{0.025}(n - 1) &= -t_{0.975}(n - 1) \\

   P(t_{0.025}(n - 1) < T(X) < -t_{0.025}(n-1)) &= 0.95 \\

   P(\overline{X} - t_{0.025}(n - 1) \frac{S}{\sqrt{n}} < \textcolor{red}{\mu} < \overline{X} + t_{0.025}(n - 1) \frac{S}{\sqrt{n}}) &= 0.95

   \end{aligned}
   ```

3. VyÄÃ­slÃ­me interval z poslednÃ­ rovnice.

- **VÄ›rohodnost / likelihood**

  Å˜Ã­kÃ¡, jak dobÅ™e nÃ¡Å¡ model (rozdÄ›lenÃ­ pravdÄ›podobnosti nÃ¡hodnÃ© veliÄiny danÃ© parametry) sedÃ­ na namÄ›Å™enÃ¡ data.

  **ğŸ“Œ NOTE**\
  PravdÄ›podobnost je funkce jevÅ¯. Likelihood je funkce parametrÅ¯ modelu.

  **ğŸ“Œ NOTE**\
  Likelihood nemusÃ­ nutnÄ› vracet ÄÃ­sla z intervalu $\lbrack 0, 1 \rbrack$.

- **Maximum likelihood estimation (MLE)**\
  Metoda odhadu parametru zaloÅ¾enÃ¡ na maximalizaci likelihoodu, Å¾e model sedÃ­ na namÄ›Å™enÃ¡ data. [mle](#mle)
- **Method of moments (MOM)**\
  Metoda odhadu parametru zaloÅ¾enÃ¡ na rovnosti teoretickÃ©ho a vÃ½bÄ›rovÃ©ho momentu. [mom](#mom)

## TestovÃ¡nÃ­ statistickÃ½ch hypotÃ©z

- **HypotÃ©za**\
  NÄ›jakÃ½ pÅ™edpoklad o datech, kterÃ½ chceme ovÄ›Å™it. ÄŒasto je formulovanÃ¡ pomocÃ­ parametrÅ¯ modelu. NapÅ™. _"stÅ™ednÃ­ hodnota je 5."_
- **TestovÃ¡nÃ­ hypotÃ©zy**\
  CÃ­lem testovÃ¡nÃ­ hypotÃ©z je ovÄ›Å™it, Å¾e data **nepopÃ­rajÃ­** nÄ›jakou hypotÃ©zu.

  - _Null hypothesis $H_0$_: "vÃ½chozÃ­ nastavenÃ­"; Äasto tvrdÃ­, Å¾e nÄ›jakÃ¡ vlastnost neexistuje.
  - _Alternative hypothesis $H_1$_: "to co, chceme dokÃ¡zat"; opak $H_0$.

  AlternativnÃ­ hypotÃ©zu _potvrzujeme_ tak, Å¾e _vyvracÃ­me_ nulovou hypotÃ©zu. Pokud se nÃ¡m nepodaÅ™Ã­ vyvrÃ¡tit $H_0$, pak o $H_1$ nevÃ­me nic. [null](#null)

  > Na testovÃ¡nÃ­ pouÅ¾ijeme statistiku $T_n = T(\mathbf{X})$, kterou nazÃ½vÃ¡me **testovacÃ­ statistikou**. MnoÅ¾inu hodnot, kterÃ© mÅ¯Å¾e testovacÃ­ statistika nabÃ½t, rozdÄ›lÃ­me na dvÄ› disjunktnÃ­ oblasti. Jednu oznaÄÃ­me $W_\alpha$, a nazveme ji **kritickou oblastÃ­** (nebo takÃ© _oblastÃ­ zamÃ­tnutÃ­ hypotÃ©zy_ (**region of rejection**, **critical region**)) a druhÃ¡ je doplÅˆkovou oblastÃ­ (oblast _nezamÃ­tnutÃ­ testovanÃ© hypotÃ©zy_).
  >
  > Na zÃ¡kladÄ› realizace nÃ¡hodnÃ©ho vÃ½bÄ›ru $\mathbf{x} = (x_1, ..., x_n)'$ vypoÄÃ­tÃ¡me hodnotu testovacÃ­ statistiky $t_n = T(\mathbf{x})$.
  >
  > - Pokud hodnota testovacÃ­ statistiky $t_n$ nabude hodnoty z kritickÃ© oblasti, t.j. $t_n = T(\mathbf{x}) \in W_\alpha$, pak **nulovou hypotÃ©zu zamÃ­tÃ¡me**.
  > - Pokud hodnota testovacÃ­ statistiky $t_n$ nabude hodnoty z oblasti nezamÃ­tnutÃ­, t.j. $t_n = T(\mathbf{x}) \not\in W_\alpha$, pak **nulovou hypotÃ©zu nezamÃ­tÃ¡me**.
  >
  > â€” MV013

**Metafora se soudem**

PlatÃ­ presumpce nevinny. PÅ™edpoklÃ¡dÃ¡me, Å¾e ÄlovÄ›k zloÄin nespÃ¡chal, dokud tuhle hypotÃ©zu nevyvrÃ¡tÃ­me.

- _$H_0$_: "ObÅ¾alovanÃ½ **neukradl** papamobil."
- _$H_1$_: "ObÅ¾alovanÃ½ **ukradl** papamobil."

- **Chyby v testovÃ¡nÃ­ hypotÃ©z**

  - _Typ I_: zamÃ­tnutÃ­ $H_0$, i kdyÅ¾ je pravdivÃ¡ -- _false positive_.
  - _Typ II_: nezamÃ­tnutÃ­ $H_0$, i kdyÅ¾ je nepravdivÃ¡ -- _false negative_.

    <dl><dt><strong>ğŸ“Œ NOTE</strong></dt><dd>

    _Positive_ = zamÃ­tnutÃ­ $H_0$, tedy potvrzenÃ­ $H_1$.

    _Negative_ = nezamÃ­tnutÃ­ $H_0$, tedy o $H_1$ nevÃ­me nic.
    </dd></dl>

- **$p$-hodnota (hladina vÃ½znamnosti)**\
  NejmenÅ¡Ã­ hladina vÃ½znamnosti $\alpha$, pÅ™i kterÃ© jeÅ¡tÄ› zamÃ­tÃ¡me $H_0$. [p-value](#p-value)

  PravdÄ›podobnost, Å¾e doÅ¡lo k chybÄ› typu I -- zavrhnuli jsme $H_0$, aÄkoli platÃ­.

  stem:[
  p = P(\text{type I error}) = P(\text{we reject } H_0 \;|\; H_0)
  ]

  **ğŸ’¡ TIP**\
   Pokud $p$-value vyjde menÅ¡Ã­ neÅ¾ poÅ¾adovanÃ¡ hladina vÃ½znamnosti $\alpha$, pak pravdÄ›podobnost, Å¾e doÅ¡lo k chybÄ› typu I je dostateÄnÄ› malÃ¡ na to, abychom mohli tvrdit, Å¾e zavrhujeme $H_0$, protoÅ¾e $H_0$ neplatÃ­, a tedy akceptujeme $H_1$.

### ParametrickÃ© testy

ParametrickÃ© testy jsou zaloÅ¾enÃ© na parametrech pravdÄ›podobnostnÃ­ch rozdÄ›lenÃ­.

- **StudentÅ¯v T-test**\
  UmoÅ¾Åˆuje ovÄ›Å™it zda normÃ¡lnÃ­ rozdÄ›lenÃ­ mÃ¡ danou stÅ™ednÃ­ hodnotu. Taky umoÅ¾Åˆuje ovÄ›Å™it zda dvÄ› normÃ¡lnÃ­ rozdÄ›lenÃ­ majÃ­ stejnou stÅ™ednÃ­ hodnotu, za pÅ™edpokladu, Å¾e majÃ­ stejnÃ½ (byÅ¥ neznÃ¡mÃ½) rozptyl. [t-test](#t-test)
- **Analysis of variance (ANOVA)**\
  Testuje rozdÃ­ly mezi stÅ™ednÃ­mi hodnotami dvou a vÃ­ce skupin. PouÅ¾Ã­vÃ¡ se k ovÄ›Å™enÃ­, zda rozptyly dvou nebo vÃ­ce mnoÅ¾in dat jsou stejnÃ© aÅ¾ na konstantnÃ­ posun a Å¡kÃ¡lovÃ¡nÃ­. [anova](#anova)

### NeparametrickÃ© testy

NeparametrickÃ© testy nejsou zaloÅ¾enÃ© (jen) na parametrech pravdÄ›podobnostnÃ­ch rozdÄ›lenÃ­. PouÅ¾Ã­vajÃ­ se, kdyÅ¾ neznÃ¡me rozdÄ›lenÃ­ dat, nebo je tÄ›Å¾kÃ© splnit pÅ™edpoklady parametrickÃ½ch testÅ¯.

- **Sign test**\
  Testuje, zda se dvÄ› nÃ¡hodnÃ© veliÄiny pÅ™i pozorovÃ¡nÃ­ liÅ¡Ã­ konzistentnÄ›. JinÃ½mi slovy, zda stÅ™enÃ­ hodnota jejich rozdÃ­lu mÃ¡ nulovÃ½ mediÃ¡n.
- **One-sample Wilcoxon signed-rank test**\
  Testuje, zda vzorky patÅ™Ã­ do symetrickÃ©ho rozdÄ›lenÃ­ s danÃ½m mediÃ¡nem.
- **PearsonÅ¯v chi-squared ($\chi^2$) test**\
  UmoÅ¾Åˆuje ovÄ›Å™it, Å¾e dvÄ› kategorickÃ© NV jsou nezÃ¡vislÃ©. [chi-squared](#chi-squared)

### Testy (ne)zÃ¡vislosti nÃ¡hodnÃ½ch veliÄin

**OpakovÃ¡nÃ­**

- **StatistickÃ¡ / stochastickÃ¡ nezÃ¡vislost**\
  NÃ¡hodnÃ© jevy $A$ a $B$ jsou stochasticky nezÃ¡vislÃ©, pokud $P(A \cap B) = P(A) \cdot P(B)$.

  **VÃ½skyt $A$ nemÃ¡ vliv na vÃ½skyt $B$.**

  - "PÅ™i pÅ™i prvnÃ­m hodu padne 6" a "pÅ™i druhÃ©m hodu padne 6" jsou **nezÃ¡vislÃ©** jevy.
  - Naproti tomu jev, Å¾e padne 6 pÅ™i prvnÃ­m hodu kostkou a jev, Å¾e souÄet ÄÃ­sel zaznamenanÃ½ch v prvnÃ­m a druhÃ©m pokusu je 8, jsou **zÃ¡vislÃ©** jevy. [nezavislost](#nezavislost)

- **NezÃ¡vislost diskrÃ©tnÃ­ch NV**

  Pokud $X$, $Y$ a $Z$ jsou diskrÃ©tnÃ­ nÃ¡hodnÃ© veliÄiny, pak definujeme $X$ a $Y$ jako _podmÃ­nÄ›nÄ› nezÃ¡vislÃ©_ vzhledem k $Z$, pokud:

  ```math
  P(X \le x, Y \le y | Z = z) = P(X \le x | Z = z) \cdot P(Y \le y | Z = z)
  ```

  pro vÅ¡echny $x$, $y$ a $z$ takovÃ©, Å¾e $P(Z = z) > 0$.

- **NezÃ¡vislost spojitÃ½ch NV**

  Pokud $X$, $Y$ a $Z$ jsou spojitÃ© nÃ¡hodnÃ© veliÄiny a majÃ­ spoleÄnou hustotu pravdÄ›podobnosti $f_{XYZ}(x,y,z)$, pak definujeme $X$ a $Y$ jako _podmÃ­nÄ›nÄ› nezÃ¡vislÃ©_ vzhledem k $Z$, pokud:

  ```math
  f_{X,Y|Z}(x,y|z) = f_{X|Z}(x|z) \cdot f_{Y|Z}(y|z)
  ```

  pro vÅ¡echna $x$, $y$ a $z$ takovÃ©, Å¾e $f_Z(z) > 0$.

> To neformÃ¡lnÄ› Å™eÄeno znamenÃ¡, Å¾e jakmile mÃ¡me k dispozici informaci obsaÅ¾enou v Z, nenÃ­ uÅ¾ dalÅ¡Ã­ informace A uÅ¾iteÄnÃ¡ pro pÅ™esnÄ›jÅ¡Ã­ poznÃ¡nÃ­ B ani znalost B nepÅ™idÃ¡ nic pro pochopenÃ­ A, i kdyby A a B byly vzÃ¡jemnÄ› zÃ¡vislÃ©.
>
> â€” Wikipedia: StatistickÃ¡ nezÃ¡vislost

- **Regrese**\
  AnalÃ½za vztahu mezi dvÄ›ma zÃ¡vislÃ½mi NV.
- **LineÃ¡rnÃ­ regrese**\
  Regrese s pÅ™edpokladem, Å¾e vztah dvÄ› NV jsou zÃ¡vislÃ© lineÃ¡rnÄ›. Rovnici regresnÃ­ pÅ™Ã­mky zapisujeme jako:

  ```math
  Y_i = \beta_0 + \beta_1 \cdot X_i + \varepsilon_i
  ```

  Kde:

  - $Y$ je NV zÃ¡vislÃ¡ na $X$,
  - $\beta_0$ je konstanta,
  - $\beta_1$ je smÄ›rnice (slope),
  - $\varepsilon_i$ je $i$-tÃ¡ pozorovanÃ¡ hodnota chyby -- nÃ¡hodnÃ¡ sloÅ¾ka / Å¡um.

  PlatÃ­:

  - $E(\varepsilon_i) = 0$,
  - $D(\varepsilon_i) = \sigma^2$,
  - $\text{cov}(\varepsilon_i, \varepsilon_j) = 0$ pro $i \neq j$,
  - $\varepsilon_i \sim N(0, \sigma^2)$ -- nÃ¡hodnÃ¡ sloÅ¾ka mÃ¡ normÃ¡lnÃ­ rozdÄ›lenÃ­,
  - regresnÃ­ parametry $\beta_0$ a $\beta_1$ mohou mÃ­t libovolnou hodnotu.

- **CelkovÃ½ F-test**\
  Pracuje s nulovou hypotÃ©zou ve tvaru:

  ```math
  H_0: \beta_1 = \beta_2 = \ldots = \beta_k = 0
  ```

  Tedy testujeme, zda hodnota analyzovanÃ© NV zÃ¡visÃ­ na lineÃ¡rnÃ­ kombinaci vysvÄ›tlujÃ­cÃ­ch NV. Pokud je $H_0$ zamÃ­tnuta, pak alespoÅˆ jedna zÃ¡vislost existuje. Pokud je $H_0$ nezamÃ­tnuta, pak je mnoÅ¾ina vysvÄ›tlujÃ­cÃ­ch NV ÃºplnÄ› blbÄ›.

  TestovÃ¡ statistika mÃ¡ F-rozdÄ›lenÃ­.

- **DÃ­lÄÃ­ t-testy**\
  UmoÅ¾ÅˆujÃ­ otestovat, Å¾e dÃ¡vÃ¡ smysl pouÅ¾Ã­t $i$-tou vysvÄ›tlujÃ­cÃ­ NV. Testujeme nulovou hypotÃ©zu:

  ```math
  H_0: \beta_i = 0
  ```

  Pokud nelze zamÃ­tnout, pak $i$-tÃ¡ vysvÄ›tlujÃ­cÃ­ NV nemÃ¡ vliv na analyzovanou NV a mÅ¯Å¾eme ji vynechat.

  TestovÃ¡ statistika mÃ¡ Studentovo t-rozdÄ›lenÃ­.

## Zdroje

- [[[statistics,1]]] [Wikipedia: Statistics](https://en.wikipedia.org/wiki/Statistics)
- [[[nv,2]]] [Wikipedia: NÃ¡hodnÃ¡ veliÄina](https://cs.wikipedia.org/wiki/N%C3%A1hodn%C3%A1_veli%C4%8Dina)
- [[[cdf,3]]] [Wikipedia: Cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function)
- [[[mean,4]]] [Wikipedia: Mean](https://en.wikipedia.org/wiki/Mean)
- [[[clv,5]]] [Wikipedia: CentrÃ¡lnÃ­ limitnÃ­ vÄ›ta](https://cs.wikipedia.org/wiki/Centr%C3%A1ln%C3%AD_limitn%C3%AD_v%C4%9Bta)
- [[[consistent-estimator,6]]] [Wikipedia: Consistent estimator](https://en.wikipedia.org/wiki/Consistent_estimator)
- [[[statistic, 7]]] [Wikipedia: Statistic](https://en.wikipedia.org/wiki/Statistic)
- [[[mle, 8]]] [Wikipedia: Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)
- [[[mom, 9]]] [Wikipedia: Method of moments](<https://en.wikipedia.org/wiki/Method_of_moments_(statistics)>)
- [[[null, 10]]] [Wikipedia: Null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis)
- [[[p-value, 11]]] [Wikipedia: P-hodnota](https://cs.wikipedia.org/wiki/P-hodnota)
- [[[mv013,12]]] [MV013 Statistics for Computer Science (jaro 2021)](https://is.muni.cz/auth/el/fi/jaro2021/MV013/)
- [[[anova, 13]]] [Wikipedia: Analysis of variance](https://en.wikipedia.org/wiki/Analysis_of_variance)
- [[[nezavislost,14]]] [Wikipedia: StatistickÃ¡ nezÃ¡vislost](https://cs.wikipedia.org/wiki/Statistick%C3%A1_nez%C3%A1vislost)
- [[[t-test, 15]]] [Wikipedia: T-test](https://cs.wikipedia.org/wiki/T-test)
- [[[chi-squared,16]]] [Chi-square tests](https://www.scribbr.com/statistics/chi-square-tests/)
- [[[moment, 17]]] [Momenty rozdÄ›lenÃ­](http://kfe.fjfi.cvut.cz/~limpouch/sigdat/pravdh/node10.html)
